### for model params #######################
model_name: deeplabv3plus_resnet101
# deeplabv3plus_mobilenet, deeplabv3plus_resnet101, deeplabv3plus_resnet50, 
# deeplabv3plus_hrnetv2_48, deeplabv3plus_hrnetv2_32, deeplabv3plus_xception
# ddrnet_39, ddrnet_23, ddrnet_23_slim
# deeplabv3_resnet101, deeplabv3_resnet50
input_height: 480
input_width: 640
input_channel: 3
weights: null #the weights enum name to load
weights_backbone: null #the backbone weights enum name to load

### for image processing #######################
preprocessing_norm: true 
image_loading_mode: 'rgb'

### for loss params. #######################
aux_loss: false

### for training params. #######################
device: cuda
device_ids: 0,1,2,3
start_epoch: 0
epochs: 3000
batch_size: 32
num_workers: 16
loss_fn: dice
optimizer: 'sgd'
lr_scheduler_type: lambda
init_lr: 0.001
momentum: 0.9
weight_decay: 0.0001
lr_warmup_epochs: 0
lr_warmup_method: linear
lr_warmup_decay: 0.01
amp: false # Mixed precision training parameters

### for debugging #######################
debug_dataset: true
debug_dataset_ratio: 0.0001

### for logging #######################
print_freq: 10
save_model_freq: 10
save_val_img: True 
save_val_img_ratio: 1
save_val_img_freq: 1
save_val_img_iou: 0.6


### for distributed training params. #######################
world_size: 1 #number of distributed processes
dist_url: env:// #url used to set up distributed training

### etc. #######################
resume: false # str >> seed_model

#Forces the use of deterministic algorithms only ?????????????????????
use_deterministic_algorithms: false
test_only: false
